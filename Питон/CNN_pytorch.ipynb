{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmvF4blMS-Iw"
      },
      "source": [
        "# Лабораторная работа №6\n",
        "\n",
        "**Сверточные нейронные сети**\n",
        "\n",
        "---\n",
        "\n",
        "**Впишите в эту ячейку ваши ФИО, группу**.\n",
        "\n",
        "ФИО:\n",
        "\n",
        "Группа:\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JW2lM4yYXio"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "В данной работе будет использоваться учебный датасет с изображениями персонажей из Симпсонов. Код для скачивания и распаковки приведен ниже, его требуется только выполнить и вo вкладке Files должна появиться папка `data`, а в ней папки `train` и `test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhBI_Y2iVHqO",
        "outputId": "fe37f0d1-8509-4ab1-bde3-0124598070c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-09 07:39:28--  http://labcolor.space/rgb-test.zip\n",
            "Resolving labcolor.space (labcolor.space)... 31.31.196.3, 2a00:f940:2:2:1:1:0:25\n",
            "Connecting to labcolor.space (labcolor.space)|31.31.196.3|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3031569 (2.9M) [application/zip]\n",
            "Saving to: ‘rgb-test.zip’\n",
            "\n",
            "rgb-test.zip        100%[===================>]   2.89M  2.90MB/s    in 1.0s    \n",
            "\n",
            "2023-11-09 07:39:30 (2.90 MB/s) - ‘rgb-test.zip’ saved [3031569/3031569]\n",
            "\n",
            "--2023-11-09 07:39:30--  http://labcolor.space/rgb-train.zip\n",
            "Resolving labcolor.space (labcolor.space)... 31.31.196.3, 2a00:f940:2:2:1:1:0:25\n",
            "Connecting to labcolor.space (labcolor.space)|31.31.196.3|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12154147 (12M) [application/zip]\n",
            "Saving to: ‘rgb-train.zip’\n",
            "\n",
            "rgb-train.zip       100%[===================>]  11.59M  8.40MB/s    in 1.4s    \n",
            "\n",
            "2023-11-09 07:39:32 (8.40 MB/s) - ‘rgb-train.zip’ saved [12154147/12154147]\n",
            "\n",
            "CPU times: user 60.2 ms, sys: 7.8 ms, total: 68 ms\n",
            "Wall time: 4.15 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "! wget -nc http://labcolor.space/rgb-test.zip\n",
        "! unzip -o -q rgb-test.zip -d data\n",
        "! wget -nc http://labcolor.space/rgb-train.zip\n",
        "! unzip -o -q rgb-train.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWExBZ0FZj1E"
      },
      "source": [
        "## Создание объекта Dataset\n",
        "\n",
        "Так как изображения в датасете организованы по папкам, где имя папки является ярлыком для данных, то мы можем воспользоваться базовым классом `ImageFolder`.\n",
        "\n",
        "Одним из параметров является `transform`, для которого необходимо скомпоновать преобразования для наших изображений. В pytorch для преобразований сейчас есть два набора функций V1 и V2 и рекомендуется использовать V2, хоть напротив многих функций указано состояние beta.\n",
        "\n",
        "Для компоновки функции из модуля v2 используйте `Compose`. Вам понадобится обязательно:\n",
        "* ToImage() - преобразование в `Image` (подкласс torch.Tensor)\n",
        "* RandomVerticalFlip() - случайное отзеркаливание\n",
        "* ToDtype(torch.float32, scale=True) - преобразование из int во float\n",
        "* Normalize() - нормализация изображений по полученным средним и стандартным отклонениям.\n",
        "\n",
        "По желанию:\n",
        "* RandomRotation() - поворот на случайный угол в указанном диапазоне\n",
        "* Можете попробовать и другие варианты преобразований. [Документация API V2](https://pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended)\n",
        "\n",
        "В качестве примера будет показана работа с созданием Dataset для получения статистик изображения. Вам же необходимо будет создать `transforms` для обучения и проверки. При обучении вы используете весь набор обязательных преобразований, при обучении вам требуется только преобразовать изображение к тензору с плавающей точкой и провести нормализацию."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s7NaAvVHH6V"
      },
      "source": [
        "### Получение статистик для нормализации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HHN2GrMjalJy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "transforms_stats = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28mPRQLMHCnd"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "stats_dataset = ImageFolder(root=\"./data/train\", transform=transforms_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F73DC1a6HByF"
      },
      "outputs": [],
      "source": [
        "imgs = [item[0] for item in stats_dataset]\n",
        "imgs = torch.stack(imgs, dim=0).numpy()\n",
        "\n",
        "mean_r = imgs[:,0,:,:].mean()\n",
        "mean_g = imgs[:,1,:,:].mean()\n",
        "mean_b = imgs[:,2,:,:].mean()\n",
        "print(f\"Means R, G, B: {mean_r,mean_g,mean_b}\")\n",
        "\n",
        "std_r = imgs[:,0,:,:].std()\n",
        "std_g = imgs[:,1,:,:].std()\n",
        "std_b = imgs[:,2,:,:].std()\n",
        "print(f\"Std R, G, B: {std_r,std_g,std_b}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z7YQmBiHehJ"
      },
      "source": [
        "**Почему значения средних и стандартных отклонений мы получаем только для обучающей выборки?**\n",
        "\n",
        "Ваш ответ:\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Используйте выведенные выше значения средних и стандартных отклонений в качестве аргументов функции `Normalize`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9zeyUxyGcrZ"
      },
      "outputs": [],
      "source": [
        "transforms_train = v2.Compose([\n",
        "#\n",
        "# Ваш код\n",
        "#\n",
        "])\n",
        "\n",
        "transforms_test = v2.Compose([\n",
        "#\n",
        "# Ваш код\n",
        "#\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVSanpdBlJpP"
      },
      "source": [
        "Теперь, когда есть необходимые `transforms` можно создать ImageFolder, указав в `root` путь до выборки и `transforms` в `transform`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnrdWtQCZHY1"
      },
      "outputs": [],
      "source": [
        "train_dataset = ImageFolder() #  Ваш код\n",
        "\n",
        "# по аналогии создайте датасет для проверочной части\n",
        "\n",
        "#\n",
        "#  Ваш код\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIMD10uQd14C"
      },
      "outputs": [],
      "source": [
        "# Выведите информацию о количестве изображений в обеих выборках и сколько классов в ваших данных.\n",
        "# Воспользуйтесь атрибутом classes для получения количества классов.\n",
        "# В объекте Dataset вы можете получить любой объект по индексу, вам будет возвращен кортеж из тензора и индекса класса.\n",
        "# shape у тензора поможет ответить на вопросы о каналах и размерах изображений.\n",
        "#\n",
        "# Ваш код\n",
        "#\n",
        "\n",
        "print(f'Количество изображений в обучающей выборке {}')\n",
        "print(f'Количество изображений в тестовой выборке {}')\n",
        "print(f'Количество классов {}')\n",
        "print(f'Количество каналов в изображении {}')\n",
        "print(f'Высота и ширина изображения {}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhGqUh4youqC"
      },
      "source": [
        "## Создание DataLoader\n",
        "\n",
        "Далее необходимо подготовить три загрузчика данных:\n",
        "\n",
        "1. Обучающий\n",
        "2. Проверочный\n",
        "3. Тестовый\n",
        "\n",
        "Тестовый загрузчик делается из тестового Dataset, а обучающий и проверочный необходимо создать, используя [SubsetRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.SubsetRandomSampler), для его работы требуется массив индексов, по которым в дальнейшем загрузчик будет в случайном порядке брать изображения и лейблы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_S19XDhmdhP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "val_size = 0.2\n",
        "\n",
        "train_samples = len(train_dataset)\n",
        "train_indices = list(range(train_samples))\n",
        "\n",
        "split_value = int(np.floor(val_size * train_samples))\n",
        "np.random.shuffle(train_indices)\n",
        "\n",
        "train_idx, val_idx = train_indices[split_value:], train_indices[:split_value]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "val_sampler = SubsetRandomSampler(val_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqeo5E_dLAD4"
      },
      "source": [
        "**Опишите своими словами, что делает каждая строчка кода в предыдущей ячейке.**\n",
        "\n",
        "Ваш ответ:\n",
        "\n",
        "1.\n",
        "2.\n",
        "3.\n",
        "4. ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq9fnX6ppC-V"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = # Ваш код\n",
        "\n",
        "train_loader = DataLoader() # не забудьте использовать нужный sampler\n",
        "\n",
        "val_loader = DataLoader() # не забудьте использовать нужный sampler\n",
        "\n",
        "test_loader = DataLoader()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdbG4_QkW1Xp"
      },
      "source": [
        "**Какую задачу решает Dataloader?**\n",
        "\n",
        "Ваш ответ:\n",
        "\n",
        "**Почему использование трех выборок (обучающей, валидационной, тестовой) считается хорошей практикой?**\n",
        "\n",
        "Ваш ответ:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1diJ0WPML5WJ"
      },
      "source": [
        "## Создание модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISx1-JU_NIFA"
      },
      "source": [
        "За основу можно взять модель LeNet-5, но скорее всего вам придется ее адаптировать под свою задачу, так как в большинстве случаев она написана под черно-белые изображения размером 32 на 32 пикселя.\n",
        "\n",
        "Сверточные нейронные сети состоят из двух частей:\n",
        "1. Слои свертки(функции свертки, активации, субдискретизации)\n",
        "2. Полносвязные слои (MLP)\n",
        "\n",
        "Слои можно объединить с помощью `nn.Sequential()`. А класс вашей модели должен наследоваться от `nn.Module`.\n",
        "\n",
        "`def forward()` определяет прямой ход и должна возвращать итоговый результат работы модели - в данном случае логиты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW3nfcAZL8XV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        # Два сверточных слоях (nn.Sequential):\n",
        "        # функция свертки (Conv2d)\n",
        "        # Функция активации\n",
        "        # Функция субдескретизации (MaxPool2d)\n",
        "        self.layer1 = nn.Sequential()\n",
        "        self.layer2 = nn.Sequential()\n",
        "\n",
        "        # Полносвязная часть\n",
        "        # Линейный слой\n",
        "        # Активация\n",
        "        # Линейный слой\n",
        "        # Активация\n",
        "        # Линейный слой - на выходе количество классов\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Из слоев и функций собираете прямой ход модели\n",
        "        # Не забудьте между сверточными слоями и полносвязными сделать уплощение\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W96DOSUzV43g"
      },
      "source": [
        "**Опишите суть операции свертки.**\n",
        "\n",
        "Ваш ответ:\n",
        "\n",
        "**Опишите суть операции субдискретизации.**\n",
        "\n",
        "Ваш ответ:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH1LAGLEN6T7"
      },
      "source": [
        "## Создание объекта модели, функции потерь и оптимизатора\n",
        "\n",
        "В качестве функции потерь будет использована перекрестная энтропия, в задании MLP вы фактически ее реализовали, но через набор отдельных функций.\n",
        "\n",
        "В качестве оптимизатора можете взять стохастический градиентный спуск или Adam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJarp7KJN6pr"
      },
      "outputs": [],
      "source": [
        "num_classes = # Ваше число\n",
        "num_epochs = 10   # Пробуйте разные значения\n",
        "learning_rate = 0.005  # Пробуйте разные значения\n",
        "\n",
        "model = ConvNet(num_classes)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "    # Ваш код\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3d1eIAOPEiJ"
      },
      "source": [
        "## Цикл обучения\n",
        "\n",
        "Попробуйте разные гиперпараметры для вашей модели. Попробуйте улучшить результат от первой попытки.\n",
        "\n",
        "Вы можете по своему желанию добавить графики потерь и точности от эпохи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLSoxR7ePE1_"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        model.train()\n",
        "\n",
        "        # Forward pass\n",
        "        # Прямой ход:\n",
        "        # Расчет вывода модели\n",
        "        # Расчет потерь\n",
        "\n",
        "        # Обнуление градиентов\n",
        "        # Обратный ход\n",
        "        # Шаг оптимизатора\n",
        "\n",
        "    print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "    # Валидация\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in ___:\n",
        "            # Расчет вывода модели\n",
        "            # С помощью torch.max можно получить индекс класса\n",
        "            # К total прибавляем количество данных в этом батче\n",
        "            # К correct прибавляем сумму совпадений между предсказанными классами и истинными\n",
        "\n",
        "        print(f'Точность (accuracy) {100 * correct / total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcqG7WGtPnCz"
      },
      "source": [
        "## Итоговая оценка\n",
        "\n",
        "Часть кода, которую вы реализовали для оценки модели на валидационной выборке, можно использовать для финальной проверки, указав нужный loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXZ7EfU7Pvtz"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in ___:\n",
        "      #\n",
        "      # Ваш код\n",
        "      #\n",
        "\n",
        "    print(f'Точность (accuracy) {100 * correct / total}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5oB2n8VyNnT"
      },
      "source": [
        "**Точность работы модели на тестовой выборке**\n",
        "\n",
        "Ваш ответ:"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
